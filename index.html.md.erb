---
title: Getting Started with Small Footprint Elastic Runtime
owner: releng
---

This documentation describes the Small Footprint Elastic Runtime tile for Pivotal Cloud Foundry (PCF). The document also describes how Small Footprint Elastic Runtime deployment differs from a standard deployment, as well as use cases and limitations.

Use Small Footprint Elastic Runtime for testing or small on-site data centers where performance is less important than cost.

<p class="note warning"><strong>WARNING: </strong>Pivotal does not recommend the Small Footprint Elastic Runtime tile for most production deployments. The tile has significant performance and capacity restraints. See <a href="#limits">Limitations</a>.</p>

## <a id='compare'></a>Differentiate Small Footprint Elastic Runtime and Elastic Runtime

The Small Footprint Elastic Runtime is a repackaging of the Elastic Runtime components into a smaller and more efficient deployment. A standard Elastic Runtime deployment must have at least 24 virtual machines (VMs), but the Small Footprint Elastic Runtime only requires four.   

The following image displays a comparison of the number of VMs deployed by Elastic Runtime and Small Footprint Elastic Runtime. 

![ERT VMs](ert-vms.png)

### <a id='usecase'></a>Use Cases

The Small Footprint Elastic Runtime tile satisfies the following use cases:

* **Small on-premise installations**: 
	* Run PCF in a small, on-site data center such as at a warehouse, retail store, hospital, or factory.
* **Proof-of-concept installations**: 
	* Deploy PCF quickly and with a small footprint for evaluation or testing purposes. 
* **Service tile R&D**: 
	* Test a service tile against Small Footprint Elastic Runtime instead of a standard Elastic Runtime deployment to increase efficiency and reduce cost.  

### <a id='limits'></a>Limitations

The Small Footprint Elastic Runtime tile has the following limitations:

* **Number of app instances**: 
	* The tile is not designed to support large numbers of app instances. You cannot scale the number of [Compute VMs](#compute) beyond `10` instances in the **Resource Config** pane.
* **Increasing platform capacity**: 
	* You cannot upgrade the Small Footprint Elastic Runtime tile to the standard Elastic Runtime tile. If you expect platform usage to increase beyond the capacity of the Small Footprint Elastic Runtime tile, Pivotal recommends using the standard Elastic Runtime tile.
* **Management plane availability during tile upgrades**
	* You may not be able to perform management plane operations for brief periods during tile upgrades, which includes deploying new apps and accessing APIs. The management plane is colocated on the [Control VM](#controlvm). 
* **App availability during tile upgrades**:
	* If you require availability during your upgrades, you must scale your **Compute VMs** to a highly available configuration. Ensure sufficient capacity exists to move app instances between Compute VM instances during the upgrade. 


## <a id='arch'></a>Architecture

You can deploy the Small Footprint Elastic Runtime tile with a minimum of four VMs, as shown in the image below.

<p class="note"><strong>Note</strong>: The following image assumes that you are using an external blobstore.</p>

![SRT VMS](srt-vms.png)

To reduce the number of VMs required for Small Footprint Elastic Runtime, the _Control_ and _Database_ VMs include colocated jobs that run on a single VM in Elastic Runtime. See the next sections for details. 

For more information about the components mentioned on this page, see the _Architecture_ section of the [Elastic Runtime Concepts](https://docs.pivotal.io/pivotalcf/concepts/index.html) guide. 

### <a id='controlvm'></a>Control VM

The Control VM includes the Elastic Runtime jobs that handle management plane operations, app lifecycles, logging, and user authorization and authentication. Additionally, all errands run on the Control VM, eliminating the need for a VM for each errand and significantly reducing the time it takes to run errands. 

The following image shows all the jobs from Elastic Runtime that are colocated on the Control VM in Small Footprint Elastic Runtime. 

![Control VMs](control-vms.png)

### <a id='dbvm'></a>Database VM

The database VM includes the Elastic Runtime jobs that handle internal storage and messaging. 

The following image shows all the jobs from Elastic Runtime that are colocated on the Database VM in Small Footprint Elastic Runtime.

![DB VMs](db-vms.png) 

### <a id='computevm'></a>Compute VM

The _Compute_ VM is the same as the Diego Cell VM in Elastic Runtime. 

![Compute VMs](compute-vms.png) 

### <a id='othervms'></a>Other VMs (Unchanged)

The following image shows the VMs performs the same functions in both versions of the Elastic Runtime tile. 

![Unchanged VMs](unchanged-vms.png) 

## <a id='install'></a>Installing Small Footprint Elastic Runtime

To install the Small Footprint Elastic Runtime tile, follow the instructions for [Installing Pivotal Cloud Foundry](https://docs.pivotal.io/pivotalcf/installing/index.html) on your IaaS. 

Follow the same installation and configuration steps as for Elastic Runtime, with the following differences:

* **Selecting a product in Pivotal Network**: When you navigate to the Elastic Runtime tile on [Pivotal Network](https://network.pivotal.io/products/elastic-runtime), select the **Small Footprint** release.

* **Securing communication between Diego and the Cloud Controller**: In the Small Footprint Elastic Runtime tile, Diego and Cloud Controller communicate securely by default.

* **Configuring resources**: The **Resource Config** pane in the Small Footprint Elastic Runtime tile reflects the differences in VMs discussed in the _Architecture_ section of this topic. 

## <a id='logs'></a>Troubleshooting Colocated Jobs using Logs

If you need to troubleshoot a job that runs on the Control or Database VMs, follow these steps:

1. Follow the procedures in _Advanced Troubleshooting with the BOSH CLI_ to  the log in to the BOSH Director for your deployment:
	1. [Gather Credential and IP Address Information](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#gather)
	1. [SSH into Ops Manager](https://docs.pivotal.io/pivotalcf/1-12/customizing/trouble-advanced.html#ssh)
	1. [Log in to the BOSH Director](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#log-in)

1. Use BOSH to list the VMs in your Small Footprint Elastic Runtime deployment:
	<pre>bosh2 -e MY-ENV -d MY-DEPLOYMENT vms</pre>
	<p class="note"><strong>Note</strong>: If you do not know the name of your deployment, you can run <code>bosh -e MY-ENV deployments</code> to list the deployments for your BOSH Director.</p>
	See the following example output:
	<pre class="terminal">
	$ bosh2 -e example-env -d example-deployment vms
	Using environment 'example-env' as client 'ops\_manager'

	Task 182. Done

	Deployment 'example-deployment'

	Instance                                               Process State  AZ             IPs        VM CID                                   VM Type
	backup-prepare/8fd07242-cf7c-4a4d-ba69-85fe078114f9    running        us-central1-a  10.0.4.10  vm-6ec72a47-55b0-4767-78af-759f1f295183  micro
	compute/01c6947d-477e-4605-9e6b-5d130a58c70c           running        us-central1-b  10.0.4.8   vm-ce14173c-d93e-414c-6830-afbe0c713fc5  xlarge.disk
	compute/28045395-5048-4c8d-8363-e22fc7b66847           running        us-central1-c  10.0.4.9   vm-e3d8f696-5802-4552-4006-a1260563ed49  xlarge.disk
	compute/2e3ed7dc-baa4-42ef-814d-980c6ab1c36b           running        us-central1-a  10.0.4.7   vm-6dc34e53-71f3-4741-674a-c42c4df9e559  xlarge.disk
	control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a           running        us-central1-a  10.0.4.6   vm-9760b74e-e13e-4483-79b6-78ab3818b628  xlarge
	ha\_proxy/b0587c68-45a8-40e2-94d3-5d2ffcdaf858          running        us-central1-a  10.0.4.11  vm-27d62bfc-af6d-4c8b-6e2a-cbba09eddd1e  micro
	mysql\_monitor/5185d04e-e038-4664-a26a-d16d0d295a7f     running        us-central1-a  10.0.4.15  vm-6d215888-913b-44a3-4db3-52329c5ada53  micro
	router/2043b22d-0c3b-4a02-873f-80a724c3ed08            running        us-central1-a  10.0.4.12  vm-2b7cf5f4-5926-4f70-6e47-d994a6eff93b  micro
	router/72b54793-e0d0-4301-8932-76da5375e654            running        us-central1-c  10.0.4.14  vm-e77bcdf1-0c26-46cd-7783-6d766f4c5098  micro
	router/e3d2ab7b-6191-46bb-ab62-c1db7268a942            running        us-central1-b  10.0.4.13  vm-3e84523b-1988-475e-49e8-de80fd76c656  micro
	database/681bcad5-fa8b-4cf1-912f-45140d96123f          running        us-central1-a  10.0.4.5   vm-e3cded4f-cf47-499f-4c96-992b3c6ebf9c  large.disk
	tcp\_router/61a06e83-a62b-4afb-b452-441dc2dc1e4c        running        us-central1-a  10.0.4.17  vm-cc1f0a62-409f-47f9-58b0-0b8f46cf9ac0  micro

	13 vms

	Succeeded
	</pre>

1. Use BOSH to SSH into one of the Small Footprint Elastic Runtime VMs.
	<pre>bosh2 -e MY-ENV -d MY-DEPLOYMENT ssh VM-NAME/GUID</pre>
	For example, to SSH into the Control VM, run the following:
	<pre class="terminal">
	$ bosh2 -e example-env -d example-deployment ssh control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a
	</pre>

1. Run `sudo su` to act as super user. 

1. Use `monit` to list the processes running on the VM. 
	<pre>monit summary</pre>
	See the following example output that lists the processes running on the Control VM. The processes listed reflect the colocation of jobs as outlined in the _Architecture_ section of this topic. 
	<pre class="terminal">
	control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a:/var/vcap/bosh\_ssh/bosh\_f9d2446b18b445e# monit summary
	The Monit daemon 5.2.5 uptime: 5d 21h 10m

	Process 'consul\_agent'              running
	Process 'bbs'                       running
	Process 'metron\_agent'              running
	Process 'locket'                    running
	Process 'route\_registrar'           running
	Process 'policy-server'             running
	Process 'silk-controller'           running
	Process 'uaa'                       running
	Process 'statsd\_injector'           running
	Process 'cloud\_controller\_ng'       running
	Process 'cloud\_controller\_worker\_local\_1' running
	Process 'cloud\_controller\_worker\_local\_2' running
	Process 'nginx\_cc'                  running
	Process 'routing-api'               running
	Process 'cloud\_controller\_clock'    running
	Process 'cloud\_controller\_worker\_1' running
	Process 'auctioneer'                running
	Process 'cc\_uploader'               running
	Process 'file\_server'               running
	Process 'nsync\_listener'            running
	Process 'ssh\_proxy'                 running
	Process 'tps\_watcher'               running
	Process 'stager'                    running
	Process 'loggregator\_trafficcontroller' running
	Process 'reverse\_log\_proxy'         running
	Process 'adapter'                   running
	Process 'doppler'                   running
	Process 'syslog\_drain\_binder'       running
	System 'system\_localhost'           running
	</pre> 

1. To access logs, navigate to `/vars/vcap/sys/log`: 
	<pre>cd /var/vcap/sys/log</pre> 

1. Run `ls` to list the log directories for each process. See the following example output from the Control VM:
	<pre class="terminal">
	control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a:/var/vcap/sys/log# ls
	adapter      cloud\_controller\_clock   file\_server                    nginx\_cc               route\_registrar  statsd\_injector      uaa\_ctl.err.log
	auctioneer   cloud\_controller\_ng      locket                         nginx\_newrelic\_plugin  routing-api      syslog\_drain\_binder  uaa\_ctl.log
	bbs          cloud\_controller\_worker  loggregator\_trafficcontroller  nsync                  silk-controller  syslog\_forwarder
	cc\_uploader  consul\_agent             metron\_agent                   policy-server          ssh\_proxy        tps
	cfdot        doppler                  monit                          reverse\_log\_proxy      stager           uaa
	</pre> 

1. Navigate to the directory of the process that you want to view logs for. For example, for the Cloud Controller process, run `cd cloud_controller_ng/`. From the directory of the process, you can list and view its logs. See the following example output:
	<pre class="terminal">
	control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a:/var/vcap/sys/log/cloud\_controller\_ng# ls
	cloud\_controller\_ng\_ctl.err.log  cloud\_controller\_ng.log.2.gz  cloud\_controller\_ng.log.6.gz         drain                  pre-start.stdout.log
	cloud\_controller\_ng\_ctl.log      cloud\_controller\_ng.log.3.gz  cloud\_controller\_ng.log.7.gz         post-start.stderr.log
	cloud\_controller\_ng.log          cloud\_controller\_ng.log.4.gz  cloud\_controller\_worker\_ctl.err.log  post-start.stdout.log
	cloud\_controller\_ng.log.1.gz     cloud\_controller\_ng.log.5.gz  cloud\_controller\_worker\_ctl.log      pre-start.stderr.log
	</pre>

## <a id='rn'></a>Release Notes

See [Small Footprint Elastic Runtime Release Notes](release-notes.html).